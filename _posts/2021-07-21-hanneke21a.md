---
title: "Online Learning with Simple Predictors and a\r Combinatorial Characterization
  of Minimax in 0/1\r Games"
abstract: "Which classes can be learned properly in the online\r model? — that is,
  by an algorithm that on each\r round uses a predictor from the concept class.\r
  While there are simple and natural cases where\r improper learning is useful and
  even necessary, it\r is natural to ask how complex must the improper\r predictors
  be in such cases.  Can one always achieve\r nearly optimal mistake/regret bounds
  using \"simple\"\r predictors?  In this work, we give a complete\r characterization
  of when this is possible, thus\r settling an open problem which has been studied\r
  since the pioneering works of Angluin (1987) and\r Littlestone (1988).  More precisely,
  given any\r concept class C and any hypothesis class H, we\r provide nearly tight
  bounds (up to a log factor) on\r the optimal mistake bounds for online learning
  C\r using predictors from H.  Our bound yields an\r exponential improvement over
  the previously best\r known bound by Chase and Freitag (2020).  As\r applications,
  we give constructive proofs showing\r that (i) in the realizable setting, a near-optimal\r
  mistake bound (up to a constant factor) can be\r attained by a sparse majority-vote
  of proper\r predictors, and (ii) in the agnostic setting, a\r near-optimal regret
  bound (up to a log factor) can\r be attained by a randomized proper algorithm.  The\r
  latter was proven non-constructively by Rakhlin,\r Sridharan, and Tewari (2015).
  \ It was also achieved\r by constructive but improper algorithms proposed by\r Ben-David,
  Pal, and Shalev-Shwartz (2009) and\r Rakhlin, Shamir, and Sridharan (2012).  A technical\r
  ingredient of our proof which may be of independent\r interest is a generalization
  of the celebrated\r Minimax Theorem (von Neumann, 1928) for binary\r zero-sum games
  with arbitrary action-sets: a simple\r game which fails to satisfy Minimax is \"Guess
  the\r Larger Number\".  In this game, each player picks a\r natural number and the
  player who picked the larger\r number wins.  Equivalently, the payoff matrix of\r
  this game is infinite triangular.  We show that this\r is the only obstruction:
  if the payoff matrix does\r not contain triangular submatrices of unbounded\r sizes
  then the Minimax theorem is satisfied.  This\r generalizes von Neumann’s Minimax
  Theorem by\r removing requirements of finiteness (or compactness)\r of the action-sets,
  and moreover it captures\r precisely the types of games of interest in online\r
  learning: namely, Littlestone games."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hanneke21a
month: 0
tex_title: "Online Learning with Simple Predictors and a\r Combinatorial Characterization
  of Minimax in 0/1\r Games"
firstpage: 2289
lastpage: 2314
page: 2289-2314
order: 2289
cycles: false
bibtex_author: Hanneke, Steve and Livni, Roi and Moran, Shay
author:
- given: Steve
  family: Hanneke
- given: Roi
  family: Livni
- given: Shay
  family: Moran
date: 2021-07-21
address:
container-title: "Proceedings of Thirty Fourth Conference on Learning\r Theory"
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/hanneke21a/hanneke21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
