---
title: On Query-efficient Planning in MDPs under Linear Realizability of the Optimal
  State-value Function
abstract: 'We consider the problem of local planning in fixed-horizon Markov Decision
  Processes (MDPs) with a generative model under the assumption that the optimal value
  function lies close to the span of a feature map. The generative model provides
  a restricted, “local” access to the MDP: The planner can ask for random transitions
  from previously returned states and arbitrary actions, and the features are also
  only accessible for the states that are encountered in this process. As opposed
  to previous work (e.g. Lattimore et al. (2020)) where linear realizability of all
  policies was assumed, we consider the significantly relaxed assumption of a single
  linearly realizable (deterministic) policy. A recent lower bound by Weisz et al.
  (2020) established that the related problem when the action-value function of the
  optimal policy is linearly realizable requires an exponential number of queries,
  either in $H$ (the horizon of the MDP) or $d$ (the dimension of the feature mapping).
  Their construction crucially relies on having an exponentially large action set.
  In contrast, in this work, we establish that $\poly(H,d)$ planning is possible with
  state value function realizability whenever the action set has a constant size.
  In particular, we present the TensorPlan algorithm which uses $\poly((dH/\delta)^A)$
  simulator queries to find a $\delta$-optimal policy relative to any deterministic
  policy for which the value function is linearly realizable with some bounded parameter
  (with a known bound). This is the first algorithm to give a polynomial query complexity
  guarantee using only linear-realizability of a single competing value function.
  Whether the computation cost is similarly bounded remains an interesting open question.
  We also extend the upper bound to the near-realizable case and to the infinite-horizon
  discounted MDP setup. The upper bounds are complemented by a lower bound which states
  that in the infinite-horizon episodic setting, planners that achieve constant suboptimality
  need exponentially many queries, either in the dimension or the number of actions.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: weisz21a
month: 0
tex_title: On Query-efficient Planning in MDPs under Linear Realizability of the Optimal
  State-value Function
firstpage: 4355
lastpage: 4385
page: 4355-4385
order: 4355
cycles: false
bibtex_author: Weisz, Gellert and Amortila, Philip and Janzer, Barnab\'as and Abbasi-Yadkori,
  Yasin and Jiang, Nan and Szepesvari, Csaba
author:
- given: Gellert
  family: Weisz
- given: Philip
  family: Amortila
- given: Barnabás
  family: Janzer
- given: Yasin
  family: Abbasi-Yadkori
- given: Nan
  family: Jiang
- given: Csaba
  family: Szepesvari
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/weisz21a/weisz21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
