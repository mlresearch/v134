---
title: "Optimizing Optimizers: Regret-optimal gradient\r descent algorithms"
abstract: "This paper treats the task of designing optimization\r algorithms as an
  optimal control problem. Using\r regret as a metric for an algorithmâ€™s performance,\r
  we study the existence, uniqueness and consistency\r of regret-optimal algorithms.
  By providing\r first-order optimality conditions for the control\r problem, we show
  that regret-optimal algorithms must\r satisfy a specific structure in their dynamics
  which\r we show is equivalent to performing\r \\emph{dual-preconditioned gradient
  descent} on the\r value function generated by its regret. Using these\r optimal
  dynamics, we provide bounds on their rates\r of convergence to solutions of convex
  optimization\r problems. Though closed-form optimal dynamics cannot\r be obtained
  in general, we present fast numerical\r methods for approximating them, generating\r
  optimization algorithms which directly optimize\r their long-term regret. These
  are benchmarked\r against commonly used optimization algorithms to\r demonstrate
  their effectiveness."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: casgrain21a
month: 0
tex_title: "Optimizing Optimizers: Regret-optimal gradient\r descent algorithms"
firstpage: 883
lastpage: 926
page: 883-926
order: 883
cycles: false
bibtex_author: Casgrain, Philippe and Kratsios, Anastasis
author:
- given: Philippe
  family: Casgrain
- given: Anastasis
  family: Kratsios
date: 2021-07-21
address:
container-title: "Proceedings of Thirty Fourth Conference on Learning\r Theory"
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/casgrain21a/casgrain21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
