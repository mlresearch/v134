---
title: "SGD Generalizes Better Than GD (And Regularization\r Doesn’t Help)"
abstract: "We give a new separation result between the\r generalization performance
  of stochastic gradient\r descent (SGD) and of full-batch gradient descent\r (GD)
  in the fundamental stochastic convex\r optimization model. While for SGD it is well-known\r
  that $O(1/\\epsilon^2)$ iterations suffice for\r obtaining a solution with $\\epsilon$
  excess expected\r risk, we show that with the same number of steps GD\r may overfit
  and emit a solution with $\\Omega(1)$\r generalization error. Moreover, we show
  that in fact\r $\\Omega(1/\\epsilon^4)$ iterations are necessary for\r GD to match
  the generalization performance of SGD,\r which is also tight due to recent work
  by Bassily et\r al. (2020). We further discuss how regularizing the\r empirical
  risk minimized by GD essentially does not\r change the above result, and revisit
  the concepts of\r stability, implicit bias and the role of the\r learning algorithm
  in generalization."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: amir21a
month: 0
tex_title: "SGD Generalizes Better Than GD (And Regularization\r Doesn’t Help)"
firstpage: 63
lastpage: 92
page: 63-92
order: 63
cycles: false
bibtex_author: Amir, Idan and Koren, Tomer and Livni, Roi
author:
- given: Idan
  family: Amir
- given: Tomer
  family: Koren
- given: Roi
  family: Livni
date: 2021-07-21
address:
container-title: "Proceedings of Thirty Fourth Conference on Learning\r Theory"
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/amir21a/amir21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
