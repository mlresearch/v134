---
title: Learning and testing junta distributions with sub cube conditioning
abstract: 'We study the problems of learning and testing junta distributions on $\{-1,1\}^n$ with respect to the uniform distribution, where a distribution $p$ is a $k$-junta if its probability mass function $p(x)$  depends on a subset of at most $k$ variables.
The main contribution is an algorithm for finding relevant coordinates in a $k$-junta distribution with subcube conditioning
(Bhattacharyya et al 2018., Canonne et al. 2019). We give two applications:
An algorithm for learning $k$-junta distributions with $\tilde{O}(k/\epsilon^2) \log n + O(2^k/\epsilon^2)$ subcube conditioning queries, and  an algorithm for testing $k$-junta distributions with $\tilde{O}((k + \sqrt{n})/\epsilon^2)$ subcube conditioning queries.
All our algorithms are optimal up to poly-logarithmic factors.

Our results show that subcube conditioning, as a natural model for accessing high-dimensional distributions, enables significant savings in
learning and testing junta distributions compared to the standard sampling model.
This addresses an open question posed by Aliakbarpour et al. 2016.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen21b
month: 0
tex_title: Learning and testing junta distributions with sub cube conditioning
firstpage: 1060
lastpage: 1113
page: 1060-1113
order: 1060
cycles: false
bibtex_author: Chen, Xi and Jayaram, Rajesh and Levi, Amit and Waingarten, Erik
author:
- given: Xi
  family: Chen
- given: Rajesh
  family: Jayaram
- given: Amit
  family: Levi
- given: Erik
  family: Waingarten
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/chen21b/chen21b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
