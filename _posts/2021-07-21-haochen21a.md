---
title: "Shape Matters: Understanding the Implicit Bias of\r the Noise Covariance"
abstract: "The noise in stochastic gradient descent (SGD)\r provides a crucial implicit
  regularization effect\r for training overparameterized models. Prior\r theoretical
  work largely focuses on spherical\r Gaussian noise, whereas empirical studies\r
  demonstrate the phenomenon that parameter-dependent\r noise — induced by mini-batches
  or label\r perturbation — is far more effective than Gaussian\r noise.  This paper
  theoretically characterizes this\r phenomenon on a quadratically-parameterized model\r
  introduced by Vaskevicius et al. and Woodworth et\r al.  We show that in an over-parameterized
  setting,\r SGD with label noise recovers the sparse\r ground-truth with an arbitrary
  initialization,\r whereas SGD with Gaussian noise or gradient descent\r overfits
  to dense solutions with large norms. Our\r analysis reveals that parameter-dependent
  noise\r introduces a bias towards local minima with smaller\r noise variance, whereas
  spherical Gaussian noise\r does not."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: haochen21a
month: 0
tex_title: "Shape Matters: Understanding the Implicit Bias of\r the Noise Covariance"
firstpage: 2315
lastpage: 2357
page: 2315-2357
order: 2315
cycles: false
bibtex_author: HaoChen, Jeff Z. and Wei, Colin and Lee, Jason and Ma, Tengyu
author:
- given: Jeff Z.
  family: HaoChen
- given: Colin
  family: Wei
- given: Jason
  family: Lee
- given: Tengyu
  family: Ma
date: 2021-07-21
address:
container-title: "Proceedings of Thirty Fourth Conference on Learning\r Theory"
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/haochen21a/haochen21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
