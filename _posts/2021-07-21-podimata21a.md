---
title: Adaptive Discretization for Adversarial Lipschitz Bandits
abstract: Lipschitz bandits is a prominent version of multi-armed bandits that studies
  large, structured action spaces such as the [0,1] interval, where similar actions
  are guaranteed to have similar rewards. A central theme here is the adaptive discretization
  of the action space, which gradually "zooms in" on the more promising regions thereof.
  The goal is to take advantage of "nicer" problem instances, while retaining near-optimal
  worst-case performance. While the stochastic version of the problem is well-understood,
  the general version with adversarial rewards is not. We provide the first algorithm
  for adaptive discretization in the adversarial version, and derive instance-dependent
  regret bounds. In particular, we recover the worst-case optimal regret bound for
  the adversarial version, and the instance-dependent regret bound for the stochastic
  version.  A version with full proofs (and additional results) appears at arxiv.org/abs/2006.12367v2.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: podimata21a
month: 0
tex_title: Adaptive Discretization for Adversarial Lipschitz Bandits
firstpage: 3788
lastpage: 3805
page: 3788-3805
order: 3788
cycles: false
bibtex_author: Podimata, Chara and Slivkins, Alex
author:
- given: Chara
  family: Podimata
- given: Alex
  family: Slivkins
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/podimata21a/podimata21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
