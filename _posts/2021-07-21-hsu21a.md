---
title: "On the Approximation Power of Two-Layer Networks of\r Random ReLUs"
abstract: "This paper considers the following question: how\r well can depth-two ReLU
  networks with randomly\r initialized bottom-level weights represent smooth\r functions?
  We give near-matching upper- and\r lower-bounds for L2-approximation in terms of
  the\r Lipschitz constant, the desired accuracy, and the\r dimension of the problem,
  as well as similar results\r in terms of Sobolev norms. Our positive results\r employ
  tools from harmonic analysis and ridgelet\r representation theory, while our lower-bounds
  are\r based on (robust versions of) dimensionality\r arguments."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hsu21a
month: 0
tex_title: "On the Approximation Power of Two-Layer Networks of\r Random ReLUs"
firstpage: 2423
lastpage: 2461
page: 2423-2461
order: 2423
cycles: false
bibtex_author: Hsu, Daniel and Sanford, Clayton H and Servedio, Rocco and Vlatakis-Gkaragkounis,
  Emmanouil Vasileios
author:
- given: Daniel
  family: Hsu
- given: Clayton H
  family: Sanford
- given: Rocco
  family: Servedio
- given: Emmanouil Vasileios
  family: Vlatakis-Gkaragkounis
date: 2021-07-21
address:
container-title: "Proceedings of Thirty Fourth Conference on Learning\r Theory"
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/hsu21a/hsu21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
