---
title: On the Minimal Error of Empirical Risk Minimization
abstract: We study the minimal squared error of the Empirical Risk Minimization (ERM)
  procedure in the task of regression, both in random and fixed design settings. Our
  sharp lower bounds shed light on the possibility (or impossibility) of adapting
  to simplicity of the model generating the data. In the fixed design setting, we
  show that the error is governed by the global complexity of the entire class. In
  contrast, in random design, ERM may only adapt to simpler models if the local neighborhoods
  around the regression function are nearly as complex as the class itself, a somewhat
  counter-intuitive conclusion. We provide sharp lower bounds for performance of ERM
  in Donsker and non-Donsker classes. We also discuss our results through the lens
  of recent studies on interpolation in overparameterized models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kur21a
month: 0
tex_title: On the Minimal Error of Empirical Risk Minimization
firstpage: 2849
lastpage: 2852
page: 2849-2852
order: 2849
cycles: false
bibtex_author: Kur, Gil and Rakhlin, Alexander
author:
- given: Gil
  family: Kur
- given: Alexander
  family: Rakhlin
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/kur21a/kur21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
