---
title: Learning to Stop with Surprisingly Few Samples
abstract: "We consider a discounted infinite horizon optimal\r stopping problem. If
  the underlying distribution is\r known a priori, the solution of this problem is\r
  obtained via dynamic programming (DP) and is given\r by a well known threshold rule.
  When information on\r this distribution is lacking, a natural (though\r naive) approach
  is “explore-then-exploit,\" whereby\r the unknown distribution or its parameters
  are\r estimated over an initial exploration phase, and\r this estimate is then used
  in the DP to determine\r actions over the residual exploitation phase. We\r show:
  (i) with proper tuning, this approach leads to\r performance comparable to the full
  information DP\r solution; and (ii) despite common wisdom on the\r sensitivity of
  such “plug in\" approaches in DP due\r to propagation of estimation errors, a surprisingly\r
  “short\" (logarithmic in the horizon) exploration\r horizon suffices to obtain said
  performance.  In\r cases where the underlying distribution is\r heavy-tailed, these
  observations are even more\r pronounced: a single sample exploration phase\r suffices."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang21a
month: 0
tex_title: Learning to Stop with Surprisingly Few Samples
firstpage: 3887
lastpage: 3888
page: 3887-3888
order: 3887
cycles: false
bibtex_author: Zhang, Tianyi and Russo, Daniel and Zeevi, Assaf
author:
- given: Tianyi
  family: Zhang
- given: Daniel
  family: Russo
- given: Assaf
  family: Zeevi
date: 2021-07-21
address:
container-title: "Proceedings of Thirty Fourth Conference on Learning\r Theory"
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/zhang21a/zhang21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
