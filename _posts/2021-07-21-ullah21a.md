---
title: Machine Unlearning via Algorithmic Stability
abstract: We study the problem of machine unlearning and identify a notion of algorithmic
  stability, Total Variation (TV) stability, which we argue, is suitable for the goal
  of exact unlearning. For convex risk minimization problems, we design TV-stable
  algorithms based on noisy Stochastic Gradient Descent (SGD). Our key contribution
  is the design of corresponding efficient unlearning algorithms, which are based
  on constructing a near-maximal coupling of Markov chains for the noisy SGD procedure.
  To understand the trade-offs between accuracy and unlearning efficiency, we give
  upper and lower bounds on excess empirical and populations risk of TV stable algorithms
  for convex risk minimization. Our techniques generalize to arbitrary non-convex
  functions, and our algorithms are differentially private as well.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ullah21a
month: 0
tex_title: Machine Unlearning via Algorithmic Stability
firstpage: 4126
lastpage: 4142
page: 4126-4142
order: 4126
cycles: false
bibtex_author: Ullah, Enayat and Mai, Tung and Rao, Anup and Rossi, Ryan A. and Arora,
  Raman
author:
- given: Enayat
  family: Ullah
- given: Tung
  family: Mai
- given: Anup
  family: Rao
- given: Ryan A.
  family: Rossi
- given: Raman
  family: Arora
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/ullah21a/ullah21a.pdf
extras: 
- label: Supplementary
  link: http://proceedings.mlr.press/v134/ullah21a/ullah21a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
