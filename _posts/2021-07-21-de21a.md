---
title: Weak learning convex sets under normal distributions
abstract: 'This paper addresses the following natural question: can efficient algorithms
  weakly learn convex sets under normal distributions? Strong learnability of convex
  sets under normal distributions is well understood, with near-matching upper and
  lower bounds given by Klivans et al (2008), but prior to the current work nothing
  seems to have been known about weak learning. We essentially answer this question,
  giving near-matching algorithms and lower bounds.  For our positive result, we give
  a poly(n)-time algorithm that can weakly learn the class of convex sets to advantage
  $\Omega(1/\sqrt{n})$ using only random examples drawn from the background Gaussian
  distribution. Our algorithm and analysis are based on a new “density increment”
  result for convex sets, which we prove using tools from isoperimetry.  We also give
  an information-theoretic lower bound showing that $O(\log(n)/\sqrt{n})$ advantage
  is best possible even for algorithms that are allowed to make poly(n) many membership
  queries.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: de21a
month: 0
tex_title: Weak learning convex sets under normal distributions
firstpage: 1399
lastpage: 1428
page: 1399-1428
order: 1399
cycles: false
bibtex_author: De, Anindya and Servedio, Rocco
author:
- given: Anindya
  family: De
- given: Rocco
  family: Servedio
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/de21a/de21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
