---
title: Regret Minimization in Heavy-Tailed Bandits
abstract: We revisit the classic regret-minimization problem in the stochastic multi-armed
  bandit setting when the arm-distributions are allowed to be heavy-tailed. Regret
  minimization has been well studied in simpler settings of either bounded support
  reward distributions or distributions that belong to a single parameter exponential
  family. We work under the much weaker assumption that the moments of order \((1+\epsilon)\){are}
  uniformly bounded by a known constant \(B\), for some given \( \epsilon > 0\). We
  propose an optimal algorithm that matches the lower bound exactly in the first-order
  term. We alsoÂ give a finite-time bound on its regret. We show that our index concentrates
  faster than the well-known truncated or trimmed empirical mean estimators for the
  mean of heavy-tailed distributions. Computing our index can be computationally demanding.
  To address this, we develop a batch-based algorithm that is optimal up to a multiplicative
  constant depending on the batch size. We hence provide a controlled trade-off between
  statistical optimality and computational cost.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: agrawal21a
month: 0
tex_title: Regret Minimization in Heavy-Tailed Bandits
firstpage: 26
lastpage: 62
page: 26-62
order: 26
cycles: false
bibtex_author: Agrawal, Shubhada and Juneja, Sandeep K and Koolen, Wouter M
author:
- given: Shubhada
  family: Agrawal
- given: Sandeep K
  family: Juneja
- given: Wouter M
  family: Koolen
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/agrawal21a/agrawal21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
