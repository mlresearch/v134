---
title: "Non-Euclidean Differentially Private Stochastic\r Convex Optimization"
abstract: "Differentially private (DP) stochastic convex\r optimization (SCO) is a
  fundamental problem, where\r the goal is to approximately minimize the population\r
  risk with respect to a convex loss function, given a\r dataset of i.i.d. samples
  from a distribution, while\r satisfying differential privacy with respect to the\r
  dataset. Most of the existing works in the\r literature of private convex optimization
  focus on\r the Euclidean (i.e., $\\ell_2$) setting, where the\r loss is assumed
  to be Lipschitz (and possibly\r smooth) w.r.t. the $\\ell_2$ norm over a constraint\r
  set with bounded $\\ell_2$ diameter. Algorithms based\r on noisy stochastic gradient
  descent (SGD) are known\r to attain the optimal excess risk in this setting.\r In
  this work, we conduct a systematic study of\r DP-SCO for $\\ell_p$-setups. For $p=1$,
  under a\r standard smoothness assumption, we give a new\r algorithm with nearly
  optimal excess risk. This\r result also extends to general polyhedral norms and\r
  feasible sets. For $p\\in(1, 2)$, we give two new\r algorithms, whose central building
  block is a novel\r privacy mechanism, which generalizes the Gaussian\r mechanism.
  Moreover, we establish a lower bound on\r the excess risk for this range of $p$,
  showing a\r necessary dependence on $\\sqrt{d}$, where $d$ is the\r dimension of
  the space. Our lower bound implies a\r sudden transition of the excess risk at $p=1$,
  where\r the dependence on $d$ changes from logarithmic to\r polynomial, resolving
  an open question in prior work\r \\citep{TTZ15a}. For $p\\in (2, \\infty)$, noisy
  SGD\r attains optimal excess risk in the low-dimensional\r regime; in particular,
  this proves the optimality of\r noisy SGD for $p=\\infty$. Our work draws upon\r
  concepts from the geometry of normed spaces, such as\r the notions of regularity,
  uniform convexity, and\r uniform smoothness."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bassily21a
month: 0
tex_title: "Non-Euclidean Differentially Private Stochastic\r Convex Optimization"
firstpage: 474
lastpage: 499
page: 474-499
order: 474
cycles: false
bibtex_author: Bassily, Raef and Guzman, Cristobal and Nandi, Anupama
author:
- given: Raef
  family: Bassily
- given: Cristobal
  family: Guzman
- given: Anupama
  family: Nandi
date: 2021-07-21
address:
container-title: "Proceedings of Thirty Fourth Conference on Learning\r Theory"
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/bassily21a/bassily21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
