---
title: Adversarially Robust Low Dimensional Representations
abstract: 'Many machine learning systems are vulnerable to small perturbations made
  to inputs either at test time or at training time. This has received much recent
  interest on the empirical front due to applications where reliability and security
  are critical. However, theoretical understanding of algorithms that are robust to
  adversarial perturbations is limited.  In this work we focus on Principal Component
  Analysis (PCA), a ubiquitous algorithmic primitive in machine learning.  We formulate
  a natural robust variant of PCA where the goal is to find a low dimensional subspace
  to represent the given data with minimum projection error, that is in addition robust
  to small perturbations measured in $\ell_q$ norm (say $q=\infty$). Unlike PCA which
  is solvable in polynomial time, our formulation is computationally intractable to
  optimize as it captures a variant of the well-studied sparse PCA objective as a
  special case. We show the following results: 1. Polynomial time algorithm that is
  constant factor competitive in the worst-case with respect to the best subspace,
  in terms of the projection error and the robustness criterion.  2. We show that
  our algorithmic techniques can also be made robust to adversarial training-time
  perturbations, in addition to yielding representations that are robust to adversarial
  perturbations at test time. Specifically, we design algorithms for a strong notion
  of training-time perturbations, where every point is adversarially perturbed up
  to a specified amount.  3. We illustrate the broad applicability of our algorithmic
  techniques in addressing robustness to adversarial perturbations, both at training
  time and test time. In particular, our adversarially robust PCA primitive leads
  to computationally efficient and robust algorithms for both unsupervised and supervised
  learning problems such as clustering and learning adversarially robust classifiers.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: awasthi21a
month: 0
tex_title: Adversarially Robust Low Dimensional Representations
firstpage: 237
lastpage: 325
page: 237-325
order: 237
cycles: false
bibtex_author: Awasthi, Pranjal and Chatziafratis, Vaggos and Chen, Xue and Vijayaraghavan,
  Aravindan
author:
- given: Pranjal
  family: Awasthi
- given: Vaggos
  family: Chatziafratis
- given: Xue
  family: Chen
- given: Aravindan
  family: Vijayaraghavan
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/awasthi21a/awasthi21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
