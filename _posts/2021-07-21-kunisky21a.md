---
title: "Hypothesis testing with low-degree polynomials in\r the Morris class of exponential
  families"
abstract: "Analysis of low-degree polynomial algorithms is a\r powerful, newly-popular
  method for predicting\r computational thresholds in hypothesis testing\r problems.
  One limitation of current techniques for\r this analysis is their restriction to
  Bernoulli and\r Gaussian distributions. We expand this range of\r possibilities
  by performing the low-degree analysis\r of hypothesis testing for the Morris class
  of\r natural exponential families with quadratic variance\r function, giving a unified
  treatment of Gaussian,\r Poisson, gamma (including exponential and\r chi-squared),
  binomial (including Bernoulli),\r negative binomial (including geometric), and\r
  generalized hyperbolic secant distributions. We then\r give several algorithmic
  applications.  1. In models\r where a random signal is observed through\r coordinatewise-independent
  noise applied in an\r exponential family, the success or failure of\r low-degree
  polynomials is governed by the z-score\r overlap, the inner product of z-score vectors
  with\r respect to the null distribution of two independent\r copies of the signal.
  \ 2. In the same models,\r testing with low-degree polynomials exhibits channel\r
  monotonicity: the above distributions admit a total\r ordering by computational
  cost of hypothesis\r testing, according to a scalar parameter describing\r how the
  variance depends on the mean in an\r exponential family.  3. In a spiked matrix
  model\r with a particular non-Gaussian noise distribution,\r the low-degree prediction
  is incorrect unless\r polynomials with arbitrarily large degree in\r individual
  matrix entries are permitted. This shows\r that polynomials summing over self-avoiding
  walks\r and variants thereof, as proposed recently by Ding,\r Hopkins, and Steurer
  (2020) for spiked matrix models\r with heavy-tailed noise, are strictly suboptimal
  for\r this model. Thus low-degree polynomials appear to\r offer a tradeoff between
  robustness and strong\r performance fine-tuned to specific models. Inspired\r by
  this, we suggest that a class of problems\r requiring \"exploration before inference,\"
  where an\r algorithm must first examine the input and then use\r some intermediate
  computation to choose a suitable\r inference subroutine, appears especially difficult\r
  for low-degree polynomials."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kunisky21a
month: 0
tex_title: "Hypothesis testing with low-degree polynomials in\r the Morris class of
  exponential families"
firstpage: 2822
lastpage: 2848
page: 2822-2848
order: 2822
cycles: false
bibtex_author: Kunisky, Dmitriy
author:
- given: Dmitriy
  family: Kunisky
date: 2021-07-21
address:
container-title: "Proceedings of Thirty Fourth Conference on Learning\r Theory"
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/kunisky21a/kunisky21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
