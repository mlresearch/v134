---
title: **Paper retracted by author request (see pdf for retraction notice from the authors)** Nonparametric Regression with Shallow Overparameterized Neural Networks Trained
  by GD with Early Stopping
abstract: We explore the ability of overparameterized shallow neural networks to learn
  Lipschitz regression functions with and without label noise when trained by Gradient
  Descent (GD). To avoid the problem that in the presence of noisy labels, neural
  networks trained to nearly zero training error are inconsistent on this class, we
  propose an early stopping rule that allows us to show optimal rates. This provides
  an alternative to the result of Hu et al. (2021) who studied the performance of
  $\ell_2$-regularized GD for training shallow networks in nonparametric regression
  which fully relied on the infinite-width network (Neural Tangent Kernel (NTK)) approximation.
  Here we present a simpler analysis which is based on a partitioning argument of
  the input space (as in the case of 1-nearest-neighbor rule) coupled with the fact
  that trained neural networks are smooth with respect to their inputs when trained
  by GD. In the noise-free case the proof does not rely on any kernelization and can
  be regarded as a finite-width result. In the case of label noise, by slightly modifying
  the proof, the noise is controlled using a technique of Yao, Rosasco, and Caponnetto
  (2007).
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kuzborskij21a
month: 0
tex_title: Nonparametric Regression with Shallow Overparameterized Neural Networks
  Trained by GD with Early Stopping
firstpage: 2853
lastpage: 2890
page: 2853-2890
order: 2853
cycles: false
bibtex_author: Kuzborskij, Ilja and Szepesvari, Csaba
author:
- given: Ilja
  family: Kuzborskij
- given: Csaba
  family: Szepesvari
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/kuzborskij21a/kuzborskij21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
