---
title: Last-iterate Convergence of Decentralized Optimistic Gradient Descent/Ascent
  in Infinite-horizon Competitive Markov Games
abstract: We study infinite-horizon discounted two-player zero-sum Markov games, and
  develop a decentralized algorithm that provably converges to the set of Nash equilibria
  under self-play. Our algorithm is based on running an Optimistic Gradient Descent
  Ascent algorithm on each state to learn the policies, with a critic that slowly
  learns the value of each state. To the best of our knowledge, this is the first
  algorithm in this setting that is simultaneously rational (converging to the opponentâ€™s
  best response when it uses a stationary policy), convergent (converging to the set
  of Nash equilibria under self-play), agnostic (no need to know the actions played
  by the opponent), symmetric (players taking symmetric roles in the algorithm), and
  enjoying a finite-time last-iterate convergence guarantee, all of which are desirable
  properties of decentralized algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wei21a
month: 0
tex_title: Last-iterate Convergence of Decentralized Optimistic Gradient Descent/Ascent
  in Infinite-horizon Competitive Markov Games
firstpage: 4259
lastpage: 4299
page: 4259-4299
order: 4259
cycles: false
bibtex_author: Wei, Chen-Yu and Lee, Chung-Wei and Zhang, Mengxiao and Luo, Haipeng
author:
- given: Chen-Yu
  family: Wei
- given: Chung-Wei
  family: Lee
- given: Mengxiao
  family: Zhang
- given: Haipeng
  family: Luo
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/wei21a/wei21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
