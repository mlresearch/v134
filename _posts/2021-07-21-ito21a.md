---
title: Parameter-Free Multi-Armed Bandit Algorithms with Hybrid Data-Dependent Regret
  Bounds
abstract: 'This paper presents multi-armed bandit (MAB) algorithms that work well
  in adversarial environments and that offer improved performance by exploiting inherent
  structures in such environments, as stochastic generative models, as well as small
  variations in loss vectors. The fundamental aim of this work is to overcome the
  limitation of worst-case analyses in MAB contexts. There can be found two basic
  approaches achieving this purpose: best-of-both-worlds algorithms that work well
  for both stochastic and adversarial settings, and data-dependent regret bounds that
  work well depending on certain difficulty indicators w.r.g. loss sequences. One
  remarkable study w.r.t. the best-of-both-worlds approach deals with the Tsallis-INF
  algorithm \citep{zimmert2019optimal}, which achieves nearly optimal regret bounds
  up to small constants in both settings, though such bounds have remained unproven
  for a special case of a stochastic setting with multiple optimal arms.  This paper
  offers two particular contributions: (i) We show that the Tsallis-INF algorithm
  enjoys a regret bound of a logarithmic order in the number of rounds for stochastic
  environments, even if the best arm is not unique. (ii) We provide a new algorithm
  with a new \textit{hybrid} regret bound that implies logarithmic regret in the stochastic
  regime and multiple data-dependent regret bounds in the adversarial regime, including
  bounds dependent on cumulative loss, total variation, and loss-sequence path-length.
  Both our proposed algorithm and the Tsallis-INF algorithm are based on a follow-the-regularized-leader
  (FTRL) framework with a time-varying regularizer. The analyses in this paper rely
  on \textit{skewed Bregman divergence}, which provides simple expressions of regret
  bounds for FTRL with a time-varying regularizer.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ito21a
month: 0
tex_title: Parameter-Free Multi-Armed Bandit Algorithms with Hybrid Data-Dependent
  Regret Bounds
firstpage: 2552
lastpage: 2583
page: 2552-2583
order: 2552
cycles: false
bibtex_author: Ito, Shinji
author:
- given: Shinji
  family: Ito
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/ito21a/ito21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
