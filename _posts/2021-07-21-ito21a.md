---
title: "Parameter-Free Multi-Armed Bandit Algorithms with\r Hybrid Data-Dependent
  Regret Bounds"
abstract: "This paper presents multi-armed bandit (MAB)\r algorithms that work well
  in adversarial\r environments and that offer improved performance by\r exploiting
  inherent structures in such environments,\r as stochastic generative models, as
  well as small\r variations in loss vectors. The fundamental aim of\r this work is
  to overcome the limitation of\r worst-case analyses in MAB contexts. There can be\r
  found two basic approaches achieving this purpose:\r best-of-both-worlds algorithms
  that work well for\r both stochastic and adversarial settings, and\r data-dependent
  regret bounds that work well\r depending on certain difficulty indicators\r w.r.g. loss
  sequences. One remarkable study\r w.r.t. the best-of-both-worlds approach deals
  with\r the Tsallis-INF algorithm\r \\citep{zimmert2019optimal}, which achieves nearly\r
  optimal regret bounds up to small constants in both\r settings, though such bounds
  have remained unproven\r for a special case of a stochastic setting with\r multiple
  optimal arms.  This paper offers two\r particular contributions: (i) We show that
  the\r Tsallis-INF algorithm enjoys a regret bound of a\r logarithmic order in the
  number of rounds for\r stochastic environments, even if the best arm is not\r unique.
  (ii) We provide a new algorithm with a new\r \\textit{hybrid} regret bound that
  implies\r logarithmic regret in the stochastic regime and\r multiple data-dependent
  regret bounds in the\r adversarial regime, including bounds dependent on\r cumulative
  loss, total variation, and loss-sequence\r path-length. Both our proposed algorithm
  and the\r Tsallis-INF algorithm are based on a\r follow-the-regularized-leader (FTRL)
  framework with\r a time-varying regularizer. The analyses in this\r paper rely on
  \\textit{skewed Bregman divergence},\r which provides simple expressions of regret
  bounds\r for FTRL with a time-varying regularizer."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ito21a
month: 0
tex_title: "Parameter-Free Multi-Armed Bandit Algorithms with\r Hybrid Data-Dependent
  Regret Bounds"
firstpage: 2552
lastpage: 2583
page: 2552-2583
order: 2552
cycles: false
bibtex_author: Ito, Shinji
author:
- given: Shinji
  family: Ito
date: 2021-07-21
address:
container-title: "Proceedings of Thirty Fourth Conference on Learning\r Theory"
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/ito21a/ito21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
