---
title: Open Problem: Can Single-Shuffle SGD be Better than Reshuffling SGD and GD?
abstract: 'We propose matrix norm inequalities that extend the Recht and Ré (2012) conjecture on a noncommutative AM-GM inequality, by supplementing it with another inequality that accounts for single-shuffle in stochastic finite-sum minimization. Single-shuffle is a popular without-replacement sampling scheme that shuffles only once in the beginning, but has not been studied in the Recht-Ré conjecture and the follow-up literature. Instead of focusing on general positive semidefinite matrices, we restrict our attention to positive definite matrices with small enough condition numbers, which are more relevant to matrices that arise in the analysis of SGD. For such matrices, we conjecture that the means of matrix products satisfy a series of spectral norm inequalities that imply “single-shuffle SGD converges faster than random-reshuffle SGD, which is in turn faster than with-replacement SGD and GD” in special cases.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yun21a
month: 0
tex_title: Benign Overfitting of Constant-Stepsize SGD for Linear Regression
firstpage: 4653
lastpage: 4658
page: 4653-4658
order: 4653
cycles: false
bibtex_author: Yun, Chulhee and Sra, Suvrit and Jadbabaie, Ali
author:
- given: Chulhee
  family: Yun
- given: Suvrit
  family: Sra
- given: Ali
  family: Jadbabaie
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/yun21a/yun21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
