---
title: 'Thinking Inside the Ball: Near-Optimal Minimization of the Maximal Loss'
abstract: We characterize the complexity of minimizing $\max_{i\in[N]} f_i(x)$ for
  convex, Lipschitz functions $f_1,\ldots, f_N$.  % For non-smooth functions, existing
  methods require $O(N\epsilon^{-2})$ queries to a first-order oracle to compute an
  $\epsilon$-suboptimal point and $\widetilde{O}(N\epsilon^{-1})$ queries if the $f_i$
  are $O(1/\epsilon)$-smooth.  % We develop methods with improved complexity bounds
  of $\widetilde{O}(N\epsilon^{-2/3} + \epsilon^{-8/3})$ in the non-smooth case and
  $\widetilde{O}(N\epsilon^{-2/3} + \sqrt{N}\epsilon^{-1})$ in the $O(1/\epsilon)$-smooth
  case.  % Our methods consist of a recently proposed ball optimization oracle acceleration
  algorithm (which we refine) and a careful implementation of said oracle for the
  softmax function.  % We also prove an oracle complexity lower bound scaling as $\Omega(N\epsilon^{-2/3})$,
  showing that our dependence on $N$ is optimal up to polylogarithmic factors.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: carmon21a
month: 0
tex_title: 'Thinking Inside the Ball: Near-Optimal Minimization of the Maximal Loss'
firstpage: 866
lastpage: 882
page: 866-882
order: 866
cycles: false
bibtex_author: Carmon, Yair and Jambulapati, Arun and Jin, Yujia and Sidford, Aaron
author:
- given: Yair
  family: Carmon
- given: Arun
  family: Jambulapati
- given: Yujia
  family: Jin
- given: Aaron
  family: Sidford
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/carmon21a/carmon21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
