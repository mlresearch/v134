---
title: "(Nearly) Dimension Independent Private ERM with\r AdaGrad Rates\\{via Publicly
  Estimated Subspaces"
abstract: "We revisit the problem of empirical risk\r minimziation (ERM) with differential
  privacy. We\r show that noisy AdaGrad, given appropriate knowledge\r and conditions
  on the subspace from which gradients\r can be drawn, achieves a regret comparable
  to\r traditional AdaGrad plus a well-controlled term due\r to noise. We show a convergence
  rate of\r $O(\\tr(G_T)/T)$, where $G_T$ captures the geometry\r of the gradient
  subspace. Since\r $\\tr(G_T)=O(\\sqrt{T})$ we can obtain faster rates\r for convex
  and Lipschitz functions, compared to the\r $O(1/\\sqrt{T})$ rate achieved by known
  versions of\r noisy (stochastic) gradient descent with comparable\r noise variance.
  In particular, we show that if the\r gradients lie in a known constant rank subspace,
  and\r assuming algorithmic access to an envelope which\r bounds decaying sensitivity,
  one can achieve faster\r convergence to an excess empirical risk of $\\tilde\r O(1/\\epsilon
  n)$, where $\\epsilon$ is the privacy\r budget and $n$ the number of samples. Letting
  $p$ be\r the problem dimension, this result implies that, by\r running noisy Adagrad,
  we can bypass the DP-SGD\r bound $\\tilde O(\\sqrt{p}/\\epsilon n)$ in\r $T=(\\epsilon
  n)^{2/(1+2\\alpha)}$ iterations, where\r $\\alpha \\geq 0$ is a parameter controlling
  gradient\r norm decay, instead of the rate achieved by SGD of\r $T=\\epsilon^2n^2$.
  Our results operate with general\r convex functions in both constrained and\r unconstrained
  minimization.  Along the way, we do a\r perturbation analysis of noisy AdaGrad,
  which is of\r independent interest. Our utility guarantee for the\r private ERM
  problem follows as a corollary to the\r regret guarantee of noisy AdaGrad."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kairouz21a
month: 0
tex_title: "(Nearly) Dimension Independent Private ERM with\r AdaGrad Rates\\\\{via}
  Publicly Estimated Subspaces"
firstpage: 2717
lastpage: 2746
page: 2717-2746
order: 2717
cycles: false
bibtex_author: Kairouz, Peter and Diaz, Monica Ribero and Rush, Keith and Thakurta,
  Abhradeep
author:
- given: Peter
  family: Kairouz
- given: Monica Ribero
  family: Diaz
- given: Keith
  family: Rush
- given: Abhradeep
  family: Thakurta
date: 2021-07-21
address:
container-title: "Proceedings of Thirty Fourth Conference on Learning\r Theory"
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/kairouz21a/kairouz21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
