---
title: "(Nearly) Dimension Independent Private ERM with AdaGrad Rates\\{via Publicly
  Estimated Subspaces"
abstract: We revisit the problem of empirical risk minimziation (ERM) with differential
  privacy. We show that noisy AdaGrad, given appropriate knowledge and conditions
  on the subspace from which gradients can be drawn, achieves a regret comparable
  to traditional AdaGrad plus a well-controlled term due to noise. We show a convergence
  rate of $O(\tr(G_T)/T)$, where $G_T$ captures the geometry of the gradient subspace.
  Since $\tr(G_T)=O(\sqrt{T})$ we can obtain faster rates for convex and Lipschitz
  functions, compared to the $O(1/\sqrt{T})$ rate achieved by known versions of noisy
  (stochastic) gradient descent with comparable noise variance. In particular, we
  show that if the gradients lie in a known constant rank subspace, and assuming algorithmic
  access to an envelope which bounds decaying sensitivity, one can achieve faster
  convergence to an excess empirical risk of $\tilde O(1/\epsilon n)$, where $\epsilon$
  is the privacy budget and $n$ the number of samples. Letting $p$ be the problem
  dimension, this result implies that, by running noisy Adagrad, we can bypass the
  DP-SGD bound $\tilde O(\sqrt{p}/\epsilon n)$ in $T=(\epsilon n)^{2/(1+2\alpha)}$
  iterations, where $\alpha \geq 0$ is a parameter controlling gradient norm decay,
  instead of the rate achieved by SGD of $T=\epsilon^2n^2$. Our results operate with
  general convex functions in both constrained and unconstrained minimization.  Along
  the way, we do a perturbation analysis of noisy AdaGrad, which is of independent
  interest. Our utility guarantee for the private ERM problem follows as a corollary
  to the regret guarantee of noisy AdaGrad.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kairouz21a
month: 0
tex_title: "(Nearly) Dimension Independent Private ERM with AdaGrad Rates\\\\{via}
  Publicly Estimated Subspaces"
firstpage: 2717
lastpage: 2746
page: 2717-2746
order: 2717
cycles: false
bibtex_author: Kairouz, Peter and Diaz, Monica Ribero and Rush, Keith and Thakurta,
  Abhradeep
author:
- given: Peter
  family: Kairouz
- given: Monica Ribero
  family: Diaz
- given: Keith
  family: Rush
- given: Abhradeep
  family: Thakurta
date: 2021-07-21
address:
container-title: Proceedings of Thirty Fourth Conference on Learning Theory
volume: '134'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 7
  - 21
pdf: http://proceedings.mlr.press/v134/kairouz21a/kairouz21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
